{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import division, I think I had an issue running this with python 2. This makes divide sign work properly\n",
    "#I have upgraded to python 3, but this is still run as python 2.Let me know if this causes an issue for you.\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_0', 'class_1', 'class_2']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the unkwown wine file, as well as the wine dataset from sklearn\n",
    "infile = 'unknown_wine.csv'\n",
    "unknownwine = pd.read_csv(infile,sep=(','))\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "wine.target\n",
    "targetnamelist = list(wine.target_names)\n",
    "targetnamelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "# Feature matrix in a object named X\n",
    "X = wine.data\n",
    "# response vector in a object named y\n",
    "y = wine.target\n",
    "#print the shape of X and Y\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the splitter (train/test) and the scaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#split the dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n",
    "#Scale the data to normalise\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "(36, 13)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of train and test objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[2, 1, 1.0, 6]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[2, 2, 0.9722222222222222, 7]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[2, 3, 0.9166666666666666, 8]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9166666666666666\t0.9565217391304348\n",
      "1\t0.8461538461538461\t0.9166666666666666\t0.8799999999999999\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[2, 4, 0.9722222222222222, 9]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[2, 5, 0.9444444444444444, 10]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "1\t0.9230769230769231\t0.9230769230769231\t0.9230769230769231\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[3, 1, 0.9722222222222222, 11]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[3, 2, 0.9722222222222222, 12]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[3, 3, 0.9444444444444444, 13]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "1\t0.9230769230769231\t0.9230769230769231\t0.9230769230769231\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[3, 4, 1.0, 14]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[3, 5, 0.9722222222222222, 15]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[4, 1, 0.9722222222222222, 16]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[4, 2, 1.0, 17]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[4, 3, 0.9444444444444444, 18]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "1\t0.9230769230769231\t0.9230769230769231\t0.9230769230769231\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[4, 4, 0.9722222222222222, 19]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[4, 5, 0.9722222222222222, 20]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[5, 1, 0.9722222222222222, 21]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[5, 2, 1.0, 22]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[5, 3, 1.0, 23]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[5, 4, 1.0, 24]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy,random_state\n",
      "[5, 5, 0.9722222222222222, 25]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "1\t1.0\t0.9285714285714286\t0.962962962962963\n",
      "2\t0.9230769230769231\t1.0\t0.9600000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#import metrics model to check the accuracy \n",
    "from sklearn import metrics\n",
    "\n",
    "#initialize lists, goodfit saves node, layer count and accuracy, goodfitMATRIX saves the confusion matrix for\n",
    "#those that have accuracy above 0.9\n",
    "#results saves the nodes/layers/score for all models\n",
    "#layers is fed to the classifier, and is changed during each for and while loop\n",
    "goodfit = []\n",
    "goodfitMATRIX = []\n",
    "results = []\n",
    "layers = []\n",
    "count_layer = 1\n",
    "first =0\n",
    "rstate_nr = 1\n",
    "for x in range(5):\n",
    "    while count_layer <6:\n",
    "        #append to the layer list ex. [1],[1,1]... then as x increases\n",
    "        #ex. [2],[2,2]...\n",
    "        layers.append(x+1)\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=layers[count_layer-1],max_iter=10000,random_state=rstate_nr)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        predictions = mlp.predict(X_test)\n",
    "        accresults = metrics.accuracy_score(y_test,predictions)\n",
    "        res = [x+1,count_layer,accresults,rstate_nr]\n",
    "        confmat = metrics.confusion_matrix(y_test, predictions)\n",
    "        if accresults >= 0.9:\n",
    "            goodfit.append(res)\n",
    "            goodfitMATRIX.append(confmat)\n",
    "            #print confmat\n",
    "            TpA = confmat[0,0]\n",
    "            TpB = confmat[1,1]\n",
    "            TpC = confmat[2,2]\n",
    "            TnA = confmat[1,1]+confmat[2,2]\n",
    "            TnB = confmat[0,0]+confmat[2,2]\n",
    "            TnC = confmat[0,0]+confmat[1,1]\n",
    "            PredA = sum(confmat[0,:])\n",
    "            PredB = sum(confmat[1,:])\n",
    "            PredC = sum(confmat[2,:])\n",
    "            FnA = sum(confmat[:,0])\n",
    "            FnB = sum(confmat[:,1])\n",
    "            FnC = sum(confmat[:,2])\n",
    "            PrecisionA = TpA / PredA\n",
    "            PrecisionB = TpB / PredB\n",
    "            PrecisionC = TpC / PredC\n",
    "            RecallA = TpB / FnB\n",
    "            RecallB = TpB / FnB\n",
    "            RecallC = TpC / FnC\n",
    "            AccuracyA = np.add(TpA,TnA) / (PredA+PredB+PredC)\n",
    "            AccuracyB = np.add(TpB,TnB) / (PredA+PredB+PredC)\n",
    "            AccuracyC = np.add(TpC,TnC) / (PredA+PredB+PredC)\n",
    "            FmeasureA = (2*RecallA*PrecisionA) / np.add(RecallA,PrecisionA)\n",
    "            FmeasureB = (2*RecallB*PrecisionB) / np.add(RecallB,PrecisionB)\n",
    "            FmeasureC = (2*RecallC*PrecisionC) / np.add(RecallC,PrecisionC)\n",
    "            print ('This model was above 0.9 accuracy\\n')\n",
    "            print ('nodes,layers,accuracy,random_state')\n",
    "            print res\n",
    "            print ('\\nClass\\tPrecision\\tRecall\\tFmeasure')\n",
    "            print ('0\\t%s\\t%s\\t%s' % (PrecisionA,RecallA,FmeasureA))\n",
    "            print ('1\\t%s\\t%s\\t%s' % (PrecisionB,RecallB,FmeasureB))\n",
    "            print ('2\\t%s\\t%s\\t%s\\n' % (PrecisionC,RecallC,FmeasureC))\n",
    "            #Because while testing I've seen that several are perfect fits\n",
    "            #I'm adding an if statement to test the first perfect fit I get on the unknown data        \n",
    "            \n",
    "            if AccuracyA==1 and AccuracyB and AccuracyC and first ==0:\n",
    "                bestx= metrics.classification_report(y_test, predictions)\n",
    "                bestowncalcs = [[PrecisionA,RecallA,FmeasureA],[PrecisionB,RecallB,FmeasureB],[PrecisionC,RecallC,FmeasureC]]\n",
    "                unkprediction = mlp.predict(unknownwine)\n",
    "                classprediction = []\n",
    "                bestfit = res[0:2]\n",
    "                bestconf= confmat\n",
    "                for i in unkprediction:\n",
    "                    tname = targetnamelist[i]\n",
    "                    classprediction.append(tname)\n",
    "                prob = mlp.predict_proba(unknownwine)\n",
    "                first =1\n",
    "        results.append(res)\n",
    "        count_layer = count_layer+1\n",
    "        rstate_nr = rstate_nr+1\n",
    "    count_layer = 1\n",
    "    layers = []\n",
    "#print results\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEKCAYAAAAPVd6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGuZJREFUeJzt3X+UXWV97/H3B5LUNkFAQiMrg4BKV8mtEH4YuOIPtBWSyiKFFAvVhhSXoRe4WNZFDbXXLOJKaRVFLIimGCDaGjAKDZIQuZHAva2hAQKBkAZiCjKJigoEMSzCzHzvH3sPnJzMnLNn5uxz9jP5vFh7Zc/+cZ5nh+F7Hr77+aGIwMzM0rVPpytgZmYj40BuZpY4B3Izs8Q5kJuZJc6B3MwscQ7kZmaJcyA3M2sxSYslPSvpsUHOS9JXJG2RtEHScTXnzpP0ZL6dV6Q8B3Izs9a7CZje4PwM4Mh8mwtcDyDpTcB84ERgGjBf0oHNCnMgNzNrsYi4D3iuwSUzgSWRWQscIOkQ4DTg7oh4LiKeB+6m8RcCAGNaUekyjBk32UNOzayQnl3bNNLPePWXWwvHnHEHv+0CspZ0v0URsWgIxU0Gnqn5uTs/NtjxhiobyM3MqioP2kMJ3PUG+uKJBscbcmrFzAygr7f4NnLdwKE1P3cB2xscb8iB3MwMoLen+DZyy4HZee+Vk4AdEfFTYBVwqqQD85ecp+bHGnJqxcwMiOhr2WdJ+jZwCjBRUjdZT5SxWTnxNWAF8MfAFmAn8Jf5ueckfQ5Yl3/Ugoho9NI0K6+q09j6ZaeZFdWKl527uh8t/rKz6x0jLq+V3CI3MwNoYYu83RzIzcygVS8xO8KB3MwM3CI3M0tdtKY3Skc4kJuZAfS5RW5mljanVszMEueXnWZmiXOL3MwscX7ZaWaWOL/sNDNLW4Rz5GZmaXOO3MwscU6tmJklzi1yM7PE9b7a6RoMmwO5mRk4tTIYSZPIVoAOYHtE/LzJ9XPJV6bWvvuzzz7jy6yemdnrnFrZnaSpwNeA/YFt+eEuSS8AF0bEQwPdV7sytVcIMrO2cot8DzcBF0TE/bUH80VGbwSOKalcM7PhcSDfw/j6IA4QEWslOV9iZpUTftm5h5WS7gSWAM/kxw4FZgN3lVSmmdnwOUe+u4i4RNIMYCbZy04B3cB1EbGijDLNzEbEqZU9RcRKYGVZn29m1lIJt8j3aXeBeRdDM7Nq6esrvlVMJwYEqQNlmpk1lnCLvBOBfFcHyjQza6wn3YUl2p5aAa7oQJlmZo1FX/GtYsoa2blhsFPApDLKNDMbkQrmvosqK7UyCTgNeL7uuIB/L6lMM7Phq2BLu6iyAvn3gQkR8XD9CUlrSirTzGz43CLfXUR8rMG5Py+jTDOzEXGL3MwscQn3WnEgNzMDiHRnznYgNzMD58jNzJKXcCDvxIAgM7PqaeGAIEnTJW2WtEXSvAHOHyZptaQNktZI6qo593lJGyVtkvQVSU2nNXEgNzMD6O0tvjUgaV/gOmAGMAU4V9KUusuuApZExNHAAuDK/N53AScDRwN/ALwTeF+zqlc2tfLy9v/b6Sq03K6rP93pKpTiQzfXj/tK353nHdjpKpRizQ2V/U++81qXWpkGbImIrQCSlpKtzfB4zTVTgEvz/XuA2/P9AN4AjCMbQDkWaLhoPbhFbmaWGcI0tpLmSnqgZqudnnsyr6+MBtmiOpPrSnsEmJXvnwnsJ+mgiPgRWWD/ab6tiohNzarur2czMxjSgKCIWAQsGuT0QDnt+r6NlwHXSpoD3AdsA3okvR04CujPmd8t6b0RcV+j+jiQm5kB0deyfuTdZGsU9+sCtu9WVsR24CwASROAWRGxI2/Zr42Il/JzK4GTyIL9oJxaMTODVq4QtA44UtIRksYB5wDLay+QNFFSf/y9HFic7/8EeJ+kMZLGkr3obJpacSA3M4OW9VqJiB7gYmAVWRC+NSI2Slog6Yz8slOAzZKeIJstdmF+fBnwY+BRsjz6IxFxR7OqO7ViZgYtHRAUESuAFXXHPluzv4wsaNff1wtcMNTyHMjNzCDpkZ0O5GZm4EmzzMyS5xa5mVniWtf9sO0cyM3MoGlvlCpzIDczA8KpFTOzxDm1YmaWOC++bGaWOLfIzcwS1+OXnWZmaXNqxcwscU6tmJmlzd0PzcxS5xb5wCRNIlurLoDtEdF0EVEzs45wIN+dpKnA14D9ydaiA+iS9AJwYUQ8VEa5ZmbDlvAQ/bJWCLoJ+EREHBURf5Rvvw/8NXDjYDfVrkx9w5Jvl1Q1M7M9RV8U3qqmrNTK+Ii4v/5gRKyVNH6wm2pXpn71l1ur97dlZqNXBQN0UWUF8pWS7gSWAM/kxw4FZgN3lVSmmdnwudfK7iLiEkkzgJlkLzsFdAPX5WvZmZlVi1vke4qIlcDKsj7fzKylEg7kZb3sHJSkue0u08ysmejtK7xVTScGBKkDZZqZNZZwi7y0QC7p98ny4/dHxEs1p54uq0wzs+GqYrfCokpJrUi6BPhX4H8Cj0maWXP678oo08xsRPqi+FYxZbXIPw4cHxEvSTocWCbp8Ii4BqdWzKyKqpf6LqysQL5vfzolIp6SdApZMD8MB3Izq6DoSTeSl9Vr5Wf5fCsA5EH9dGAi8I6SyjQzG76+IWwVU1aLfDbQU3sgInqA2ZK+XlKZZmbDlvLLzrJGdnY3OPdvZZRpZjYiFWxpF+WFJczMcIvczCx9bpGbmaUteppfU1UO5GZmQCTcIm/7pFlmZpXUwu6HkqZL2ixpi6R5A5w/TNJqSRskrZHUVXPuLZJ+IGmTpMfzQZUNOZCbmZG1yItujUjaF7gOmAFMAc6VNKXusquAJRFxNLAAuLLm3BLgCxFxFDANeLZZ3R3IzcxoXSAnC75bImJrROwClpItslNrCrA637+n/3we8MdExN2QDaaMiJ3NCqxsjnzX1Z/udBWsoE++enCnq9By4y5d2OkqlOIU/N/VYKK3+Owh+boKtWsrLMrXHIZs1tdnas51AyfWfcQjwCzgGuBMYD9JBwG/B7wg6XvAEcD/AeZFRG+j+lQ2kJuZtdNQXnbWLhQ/gIG+Eeo7qV8GXCtpDnAfsI1sNPwY4D3AscBPgFuAOcA3GtXHgdzMDIi+ls3n10222Hy/LmD7bmVFbAfOApA0AZgVETskdQPrI2Jrfu524CSaBHLnyM3MaGmOfB1wpKQjJI0DzgGW114gaaKk/vh7ObC45t4DJfXnKz8APN6sQAdyMzMgQoW3xp8TPcDFwCpgE3BrRGyUtEDSGfllpwCbJT0BTAIW5vf2kqVdVkt6lCxN80/N6u7UipkZrR0QFBErgBV1xz5bs78MWDbIvXcDRw+lPAdyMzOgbwi9VqrGgdzMjJa+7Gw7B3IzMxzIzcySF+lOR16s14qkkyWNz/c/KulL+ULKZmajQvSp8FY1RbsfXg/slHQM8CngabKJXczMRoVWdT/shKKBvCcigmxil2si4hpgv/KqZWbWXr29KrxVTdEc+a8lXQ78BfCefJrGseVVy8ysvarY0i6qaIv8z4BXgPMj4mdks3t9obRamZm12ajPkefB+7vAb+WHfgncVlalzMzaLaL4VjVFe618nGw46dfzQ5OB28uqlJlZu6XcIi+aI7+IbNWL+wEi4klJv1tarczM2qy3L905BIsG8lciYpeUfRNJGsOeE6WbmSWriimToooG8nsl/Q3w25I+CFwI3FFetczM2qtvL+i1Mg/4BfAocAHZ9Ix/W1alzMzaLeUBQYVa5BHRRza5edMJzutJelP2EfH8UO81M2uXUZtayVeoGPTxImLAyc8lvQX4PPCHwAvZIb0R+CHZitBPDXLfaytTf2XGcZx/7FsLPIKZ2cilnFpp1iI/Pf/zovzPb+Z/fgTY2eC+W4AvAx/Jly4iHw16NrCUbDHRPdSuTP2bz5yd8PejmaUm5V4rDWseEU9HxNPAyRHxqYh4NN/mAac1uHViRNzSH8Tzz+qNiKXAQa2puplZ68QQtqop2mtlvKR3R8T/A5D0LmB8g+sflPRV4GbgmfzYocB5wPrhVtbMrCyjObXS72PAYkn75z+/AJzf4PrZ+T1XkI0CFVlAvwP4xvCqamZWnir2RimqaK+VB4Fj8heWiogdTa7fRTaH+fUjr6KZWfn6Ol2BESg618r+kr5E1utktaQv1rTOh0TS6c2vMjNrr0CFt6op+pp2MfBr4MP59iJw4zDLfOcw7zMzK01PqPBWNUVz5G+LiFk1P18h6eFGN0iaRjYQaJ2kKcB04D8jYv4w62pmVpoqtrSLKhrIX67rtXIy8PJgF0uaD8wAxki6GzgRWAPMk3RsRCwcWbXNzFor5Rx50UD+P4Cba/Liz5N1JRzMnwJTyRai+BnQFREvSvoC2VS4DuRmVil7Q4t8E9mQ+7cBBwA7gD8BNgxyfU8+GGinpB9HxIsAEfGypJS/+MxslEo5MBUN5P9K1nf8IWBbget3SfqdiNgJHN9/MG/Rp/z3ZWajVO9e0CLviojpQ/jc90bEK/DazIn9xtI4JWNm1hEVXMGtsKKB/N8lvSMiHi1ycX8QH+D4L8kWbjYzq5S+vaBF/m5gjqT/Al4hG3Ifg01ja2aWmipOhlVU0UA+o9RamJl1WMov74rOtfJ02RUxM+ukPo3+1IqZ2ajW2/ySykp3SQwzsxbqU/GtGUnTJW2WtEXSvAHOHyZptaQNktZI6qo7/0ZJ2yRdW6TuDuRmZmS9VopujeTLWl5H9m5xCnBuPt9UrauAJXmHkQXAlXXnPwfcW7TuTq200bhL/6HTVSjHDZ/pdA1abtfVn+50FazNWthrZRqwJSK2AkhaCswEHq+5Zgpwab5/D3B7/wlJxwOTgLuAE4oU6Ba5mRlDS61ImivpgZptbs1HTeb1JS4BuvNjtR4B+meUPRPYT9JBkvYBvgh8cih1d4vczIyhdT+MiEXAokFOD5R7qW/wXwZcK2kOcB/Z1Cc9wIXAioh4RkPoReNAbmYG9Lau92E32WLz/bqA7bUXRMR24CwASROAWRGxQ9J/B94j6UJgAjBO0ksRsccL01oO5GZmtHRA0DrgSElHkLW0zwH+vPYCSROB5/K5qC4nW4WNiPhIzTVzgBOaBXFwjtzMDMgCedGtkYjoAS4GVpFNAX5rRGyUtEDSGfllpwCbJT1B9mJzRGs0uEVuZga0cinOiFgBrKg79tma/WXAsiafcRNwU5HyHMjNzNgL5loxMxvtUh6i70BuZsbesbCEmdmo5tSKmVniHMjNzBK3N6wQZGY2qjlHbmaWOPdaMTNLXF/CyRUHcjMz/LLTzCx56bbHHcjNzAC3yM3MktejdNvkDuRmZji10pCkNwEREc+XXZaZ2XClnFopZWEJSW+RtFTSL4D7gXWSns2PHV5GmWZmI9FHFN6qpqwVgm4BbgPeHBFHRsTbgUOA24Glg91UuzL14vVbS6qamdmeYghb1ZQVyCdGxC0R8dpgqYjojYilwEGD3RQRiyLihIg44fxj31pS1czM9tSqpd46oawc+YOSvgrcDDyTHzsUOA9YX1KZZmbD1lvJtnYxZQXy2cDHgCuAyYDIAvodwDdKKtPMbNiq2NIuqpRAHhG7gOvzzcys8iLhFnlZOfJBSTq93WWamTWTco687YEceGcHyjQza8jdDwuQtAQgIua3q0wzs6JS7n5YSo5c0vL6Q8D7JR0AEBFnlFGumdlw9VQyRBdTVq+VLuBx4AayLzABJwBfLKk8M7MR8cvOPZ0APAh8BtgREWuAlyPi3oi4t6QyzcyGLeWXnWV1P+wDrpb0nfzPn5dVlplZK6TcIi81uEZEN3C2pA8BL5ZZlpnZSFSxpV1UW1rJEXEncGc7yjIzG47ecIvczCxpVewfXpQDuZkZzpGbmSXPOXIzs8SlnFrpxFwrZmaVE0P4pxlJ0yVtlrRF0rwBzh8mabWkDZLWSOrKj0+V9CNJG/Nzf1ak7g7kZmZkvVaKbo1I2he4DpgBTAHOlTSl7rKrgCURcTSwALgyP74TmB0R/w2YDny5f2qTRhzIzcxo6eyH04AtEbE1X5thKTCz7popwOp8/57+8xHxREQ8me9vB54FDm5WoHPkNmKnblzY6SpYQbuu/nSnq1BZQ3nZKWkuMLfm0KKIWJTvT+b1JS4BuoET6z7iEWAWcA1wJrCfpIMi4lc1ZUwDxgE/blYfB3IzM4bW/TAP2osGOa0BP353lwHXSpoD3AdsA3pe+wDpEOCbwHn5lCcNOZCbmdHSXivdZIvN9+sCttdekKdNzgKQNAGYFRE78p/fSDYS/m8jYm2RAp0jNzMDIqLw1sQ64EhJR0gaB5wD7LZGg6SJkvrj7+XA4vz4OOA2sheh3yladwdyMzOglyi8NRIRPcDFwCpgE3BrRGyUtEBS/6I6pwCbJT0BTAL6XzR9GHgvMEfSw/k2tVndnVoxM6O1A4IiYgWwou7YZ2v2lwHLBrjvW8C3hlqeA7mZGRRJmVSWA7mZGWkP0XcgNzPDsx+amSXPC0uYmSXOqRUzs8Q5kJuZJc69VszMEucWuZlZ4txrxcwscb3NJxmsLAdyMzOcIzczS55z5GZmiXOO3MwscX1OrZiZpc0t8kFImkS2EGkA2yPi52WWZ2Y2XCn3WillhSBJUyWtBdYAnwe+ANwraa2k4xrcN1fSA5IeWLx+axlVMzMbUF9E4a1qymqR3wRcEBH31x6UdBJwI3DMQDfVrkz9m8+cXb2/LTMbtZxa2dP4+iAOEBFrJY0vqUwzs2GrYku7qLIC+UpJdwJLgGfyY4cCs4G7SirTzGzY3CKvExGXSJoBzCR72SmgG7guX5TUzKxSeqO301UYttJ6rUTESmBlWZ9vZtZKKQ/RL6XXSiOS5ra7TDOzZvqIwlvVdGJAkDpQpplZQym3yNsSyCW9G5gGPBYRX29HmWZmQ5Fyr5WyBgT9R83+x4Frgf2A+ZLmlVGmmdlIxBD+qZqyWuRja/bnAh+MiF9IugpYC/x9SeWamQ1LykP0ywrk+0g6kKzFr4j4BUBE/EZST0llmpkNm3Pke9ofeJDsxWZIenNE/EzSBPyy08wqKOUceVkDgg4f5FQfcGYZZZqZjYRb5AVFxE7gv9pZpplZEVXsH16UF5YwM8MtcjOz5LnXiplZ4vyy08wscSmnVto+aZaZWRW1cmSnpOmSNkvaMtBodkmHSVotaYOkNZK6as6dJ+nJfDuvSN0dyM3MyFrkRbdGJO0LXAfMAKYA50qaUnfZVcCSiDgaWABcmd/7JmA+cCLZ/FTz88GVDTmQm5nR0sWXpwFbImJrROwClpItslNrCrA637+n5vxpwN0R8VxEPA/cDUxvVmBlc+TjF36nbSNAJc3NF34eVUbjc43GZ4L2PdfYhd8pu4jXpPbvqmfXtsIxJ19XoXZthUU1zzqZ15e4hGx1tBPrPuIRYBZwDdkgyf0kHTTIvZOb1cct8sxoXexiND7XaHwmGJ3PNRqfCYCIWBQRJ9RstV9YA30h1DfjLwPeJ2k98D5gG9BT8N49VLZFbmaWqG6yxeb7dQHbay+IiO3AWQD5HFSzImKHpG7glLp71zQr0C1yM7PWWgccKekISeOAc4DltRdImiipP/5eDizO91cBp0o6MH/JeWp+rCEH8kwyebwhGo3PNRqfCUbnc43GZ2oqInqAi8kC8Cbg1ojYKGmBpDPyy04BNkt6ApgELMzvfQ74HNmXwTpgQX6sIaXcCd7MzNwiNzNLngO5mVni9ppALmmxpGclPTbIeUn6Sj6kdoOk49pdx6GSdKikeyRtkrRR0icGuCbF53qDpP+Q9Ej+XFcMcM1vSbolf677JR3e/poOnaR9Ja2X9P0BzqX6TE9JelTSw5IeGOB8cr+DqdlrAjlwE41HSM0Ajsy3ucD1bajTSPUA/ysijgJOAi4aYChwis/1CvCBiDgGmApMl3RS3TUfA56PiLcDVwP/0OY6DtcnyF6ADSTVZwJ4f0RMjYgTBjiX4u9gUvaaQB4R9wGN3v7OJJv7ICJiLXCApEPaU7vhiYifRsRD+f6vyQJE/SiwFJ8rIuKl/Mex+Vb/Vn4mcHO+vwz4Q0mVXg82nxjpQ8ANg1yS3DMVlNzvYGr2mkBewLCGxlZF/r/hxwL3151K8rnyFMTDwLNkc08M+lx5d68dwEHtreWQfRn4FNnatQNJ8Zkg+5L9gaQH86Hr9ZL8HUyJA/nrhjU0tgrykWHfBf46Il6sPz3ALZV/rojojYipZCPbpkn6g7pLknouSacDz0bEg40uG+BYZZ+pxskRcRxZCuUiSe+tO5/qcyXDgfx1TYfVVpGksWRB/J8j4nsDXJLkc/WLiBfIhijXv9947bkkjQH2p3HqrNNOBs6Q9BTZbHgfkPStumtSeybgteHmRMSzwG1ks//VSvp3MAUO5K9bDszO37CfBOyIiJ92ulKN5PnTbwCbIuJLg1yW4nMdLOmAfP+3gT8C/rPusuVA/6T7fwr8MCo8ui0iLo+Irog4nGzI9g8j4qN1lyX1TACSxkvar3+fbEh5fc+w5H4HU7PXTJol6dtkw2In5hPTzCd7iUZEfA1YAfwxsAXYCfxlZ2o6JCcDfwE8mueTAf4GeAsk/VyHADcrm6B/H7Ihzt+XtAB4ICKWk32BfVPSFrJW6zmdq+7wjYJnmgTclr+THQP8S0TcJemvIOnfwaR4iL6ZWeKcWjEzS5wDuZlZ4hzIzcwS50BuZpY4B3Izs8Q5kFtHSHqp+VVmVoQDuY06+cAT/27bXsO/7NZRkiZIWi3poXxO65n58c/Vzq8uaaGkS/L9T0pal89tfUV+7PB8XvavAg8Bh0q6SdJj+ede2onnM2sHDwiyjpD0UkRMyOcU+Z2IeFHSRGAt2bzVhwHfi4jj8tb1k2RzeBxPNnz9ArLJmJYDnwd+AmwF3hURayUdD/x9RHwwL++AfN4Ws1Fnrxmib5Ul4O/yGfP6yKY3nRQRT0n6laRjyYaBr4+IX0k6lWw+j/X5/RPIAv9PgKfz+a4hC+pvlfSPwJ3AD9r3SGbt5UBunfYR4GDg+Ih4NZ8d8A35uRuAOcCbgcX5MQFXRsTXaz8kn4/9N/0/R8Tzko4BTgMuAj4MnF/WQ5h1knPk1mn7k83T/aqk95OlVPrdRjZ97TuBVfmxVcD5+RzsSJos6XfrPzRP0+wTEd8F/jfgdSJt1HKL3Drtn4E78kV7H6ZmutqI2CXpHuCFiOjNj/1A0lHAj/IZ914CPgr01n3uZODGmt4rl5f7GGad45edVll5EH4IODsinux0fcyqyqkVqyRJU8jmr17tIG7WmFvkZmaJc4vczCxxDuRmZolzIDczS5wDuZlZ4hzIzcwS9/8BtF6QjjwxZV4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make results list into an array for plotting\n",
    "myarray = np.asarray(results)\n",
    "\n",
    "#make a dataframe with each column named for ploting\n",
    "data = pd.DataFrame({'nodes': myarray[:,0], 'layers': myarray[:,1], 'Z': myarray[:,2]})\n",
    "data_pivoted = data.pivot(\"nodes\", \"layers\", \"Z\")\n",
    "#vmin,vmax changed just to show mainly the ones above 0.9\n",
    "ax = sns.heatmap(data_pivoted,vmin=0.9, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heat map shows which models had the best accuracy. I have the z variable (accuracy) plotted from 0.9-1.0. So any that are not black were found to be above 0.9 accuracy score. \n",
    "As seen above all models showed a high accuracy score above 0.9 if the nodes used were above 1. The lighter the color the better accuracy.\n",
    "If you see in my for loop above, I put in an if statement that if I happen to have a model that is a perfect fit, which I had seen occur while testing different things. So I happened to know that there were perfect models. However, the code below still prints the best fit models if there aren't and models that have a perfect fit.\n",
    "\n",
    "I chose the first instance of a perfect model to test on the unknownwine data set, because I assume that the lowest node/layer model that is a perfect fit will be faster and more efficient than any models that are also perfect but have more nodes/layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes used 2, and layers used 1 in best fit model\n",
      "\n",
      "Confusion matrix for best fit model\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification report for best fit model\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "Own calculations (printed in cell 2 steps above as well) to verify the classification report\n",
      "\n",
      "[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]]\n",
      "Predictions for the unknownwine data using this model\n",
      "\n",
      "['class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_2', 'class_0', 'class_0']\n",
      "Probability for each class for the unknown data\n",
      "\n",
      "[[1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000 9.23125049e-238]\n",
      " [1.00000000e+000 0.00000000e+000 3.45178196e-153]\n",
      " [1.00000000e+000 5.34371771e-277 9.75519919e-093]\n",
      " [1.00000000e+000 0.00000000e+000 3.73125518e-131]\n",
      " [1.00000000e+000 7.57430851e-148 1.40435092e-043]\n",
      " [1.00000000e+000 0.00000000e+000 5.50351480e-110]\n",
      " [1.11945166e-009 3.96531250e-107 9.99999999e-001]\n",
      " [1.00000000e+000 2.00854940e-312 6.79710476e-083]\n",
      " [1.00000000e+000 1.28671354e-225 1.23673441e-074]]\n"
     ]
    }
   ],
   "source": [
    "#if there was a perfect fit then print info for the best fit model\n",
    "if first == 1:\n",
    "    print ('Nodes used %s, and layers used %s in best fit model\\n' % (bestfit[0],bestfit[1]))\n",
    "    print ('Confusion matrix for best fit model\\n')\n",
    "    print bestconf\n",
    "    print ('Classification report for best fit model\\n')\n",
    "    print bestx\n",
    "    print ('Own calculations (printed in cell 2 steps above as well) to verify the classification report\\n')\n",
    "    print (bestowncalcs)\n",
    "    print ('Predictions for the unknownwine data using this model\\n')\n",
    "    print classprediction\n",
    "    print ('Probability for each class for the unknown data\\n')\n",
    "    print prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the classification report for the best fit model I can see\n",
    "that the instances of class 0,1,2 are even. So I can assume that this\n",
    "is well balanced to use as a classifier for each class\n",
    "\n",
    "Also, looking at the probabilites of each class for each unknown printed\n",
    "above I can see that the unknown predicted has a high probability for \n",
    "being correct and the probabilites aren't too close for the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n",
      "['class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0']\n",
      "[[1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 4.05988795e-198 6.55617228e-204]\n",
      " [1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 3.39573426e-103 5.37587798e-106]\n",
      " [1.00000000e+000 3.00862822e-272 3.93451506e-280]\n",
      " [1.00000000e+000 1.91562647e-047 6.23894558e-057]\n",
      " [1.00000000e+000 2.34029622e-214 1.33594736e-216]\n",
      " [1.00000000e+000 8.99238422e-163 1.32825160e-167]]\n"
     ]
    }
   ],
   "source": [
    "#use best model to train data and return accuracy\n",
    "#this is done by hand if there was no perfect fit\n",
    "\n",
    "#This is for if there isn't a perfect fit, decide which one is the best fit\n",
    "#from the above printing of Precision, Recall, Fmeasure for each model\n",
    "#above 0.9\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100),max_iter=1000,random_state=42)\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "accresults = metrics.accuracy_score(y_test,predictions)\n",
    "print accresults\n",
    "metrics.classification_report(y_test, predictions)\n",
    "unkprediction = mlp.predict(unknownwine)\n",
    "classprediction = []\n",
    "for i in unkprediction:\n",
    "    tname = targetnamelist[i]\n",
    "    classprediction.append(tname)\n",
    "print classprediction\n",
    "print mlp.predict_proba(unknownwine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
