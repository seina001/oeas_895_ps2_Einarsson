{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import division, I think I had an issue running this with python 2. This makes divide sign work properly\n",
    "#I have upgraded to python 3, but this is still run as python 2.Let me know if this causes an issue for you.\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_0', 'class_1', 'class_2']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the unkwown wine file, as well as the wine dataset from sklearn\n",
    "infile = 'unknown_wine.csv'\n",
    "unknownwine = pd.read_csv(infile,sep=(','))\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "wine.target\n",
    "targetnamelist = list(wine.target_names)\n",
    "targetnamelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "# Feature matrix in a object named X\n",
    "X = wine.data\n",
    "# response vector in a object named y\n",
    "y = wine.target\n",
    "#print the shape of X and Y\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the splitter (train/test) and the scaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#split the dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n",
    "#Scale the data to normalise\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "(36, 13)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of train and test objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[2, 1, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[2, 2, 1.0]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[2, 3, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[3, 1, 1.0]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[3, 2, 1.0]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[3, 3, 1.0]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[3, 4, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[3, 5, 1.0]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[4, 1, 0.9444444444444444]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t0.9090909090909091\t0.9230769230769231\t0.9160305343511451\n",
      "1\t0.9230769230769231\t0.9230769230769231\t0.9230769230769231\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        36\n",
      "   macro avg       0.94      0.95      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[4, 2, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[4, 3, 1.0]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[4, 4, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[4, 5, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[5, 1, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[5, 2, 1.0]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t1.0\t1.0\t1.0\n",
      "2\t1.0\t1.0\t1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[5, 3, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[5, 4, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "This model was above 0.9 accuracy\n",
      "\n",
      "nodes,layers,accuracy\n",
      "[5, 5, 0.9722222222222222]\n",
      "\n",
      "Class\tPrecision\tRecall\tFmeasure\n",
      "0\t1.0\t1.0\t1.0\n",
      "1\t0.9285714285714286\t1.0\t0.962962962962963\n",
      "2\t1.0\t0.9230769230769231\t0.9600000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#import metrics model to check the accuracy \n",
    "from sklearn import metrics\n",
    "\n",
    "#initialize lists, goodfit saves node, layer count and accuracy, goodfitMATRIX saves the confusion matrix for\n",
    "#those that have accuracy above 0.9\n",
    "#results saves the nodes/layers/score for all models\n",
    "#layers is fed to the classifier, and is changed during each for and while loop\n",
    "goodfit = []\n",
    "goodfitMATRIX = []\n",
    "results = []\n",
    "layers = []\n",
    "count_layer = 1\n",
    "first =0\n",
    "\n",
    "for x in range(5):\n",
    "    while count_layer <6:\n",
    "        #append to the layer list ex. [1],[1,1]... then as x increases\n",
    "        #ex. [2],[2,2]...\n",
    "        layers.append(x+1)\n",
    "        #print layers\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=layers,max_iter=10000,random_state = 4)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        predictions = mlp.predict(X_test)\n",
    "        accresults = metrics.accuracy_score(y_test,predictions)\n",
    "        res = [x+1,count_layer,accresults]\n",
    "        confmat = metrics.confusion_matrix(y_test, predictions)\n",
    "        #print confmat\n",
    "        if accresults >= 0.9:\n",
    "            goodfit.append(res)\n",
    "            goodfitMATRIX.append(confmat)\n",
    "            #print confmat\n",
    "            TpA = confmat[0,0]\n",
    "            TpB = confmat[1,1]\n",
    "            TpC = confmat[2,2]\n",
    "            TnA = confmat[1,1]+confmat[2,2]\n",
    "            TnB = confmat[0,0]+confmat[2,2]\n",
    "            TnC = confmat[0,0]+confmat[1,1]\n",
    "            PredA = sum(confmat[:,0])\n",
    "            PredB = sum(confmat[:,1])\n",
    "            PredC = sum(confmat[:,2])\n",
    "            FnA = sum(confmat[0,:])\n",
    "            FnB = sum(confmat[1,:])\n",
    "            FnC = sum(confmat[2,:])\n",
    "            PrecisionA = TpA / PredA\n",
    "            PrecisionB = TpB / PredB\n",
    "            PrecisionC = TpC / PredC\n",
    "            RecallA = TpB / FnB\n",
    "            RecallB = TpB / FnB\n",
    "            RecallC = TpC / FnC\n",
    "            AccuracyA = np.add(TpA,TnA) / (PredA+PredB+PredC)\n",
    "            AccuracyB = np.add(TpB,TnB) / (PredA+PredB+PredC)\n",
    "            AccuracyC = np.add(TpC,TnC) / (PredA+PredB+PredC)\n",
    "            FmeasureA = (2*RecallA*PrecisionA) / np.add(RecallA,PrecisionA)\n",
    "            FmeasureB = (2*RecallB*PrecisionB) / np.add(RecallB,PrecisionB)\n",
    "            FmeasureC = (2*RecallC*PrecisionC) / np.add(RecallC,PrecisionC)\n",
    "            print ('This model was above 0.9 accuracy\\n')\n",
    "            print ('nodes,layers,accuracy')\n",
    "            print res\n",
    "            print ('\\nClass\\tPrecision\\tRecall\\tFmeasure')\n",
    "            print ('0\\t%s\\t%s\\t%s' % (PrecisionA,RecallA,FmeasureA))\n",
    "            print ('1\\t%s\\t%s\\t%s' % (PrecisionB,RecallB,FmeasureB))\n",
    "            print ('2\\t%s\\t%s\\t%s\\n' % (PrecisionC,RecallC,FmeasureC))\n",
    "            print metrics.classification_report(y_test, predictions)\n",
    "            \n",
    "            #Because while testing I've seen that several are perfect fits\n",
    "            #I'm adding an if statement to test the first perfect fit I get on the unknown data        \n",
    "            \n",
    "            if AccuracyA==1 and AccuracyB and AccuracyC and first ==0:\n",
    "                bestx= metrics.classification_report(y_test, predictions)\n",
    "                bestowncalcs = [[PrecisionA,RecallA,FmeasureA],[PrecisionB,RecallB,FmeasureB],[PrecisionC,RecallC,FmeasureC]]\n",
    "                unkprediction = mlp.predict(unknownwine)\n",
    "                classprediction = []\n",
    "                bestfit = res[0:2]\n",
    "                bestconf= confmat\n",
    "                for i in unkprediction:\n",
    "                    tname = targetnamelist[i]\n",
    "                    classprediction.append(tname)\n",
    "                prob = mlp.predict_proba(unknownwine)\n",
    "                first =1\n",
    "        results.append(res)\n",
    "        count_layer = count_layer+1\n",
    "        \n",
    "    count_layer = 1\n",
    "    layers = []\n",
    "#print results\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make results list into an array for plotting\n",
    "myarray = np.asarray(results)\n",
    "\n",
    "#make a dataframe with each column named for ploting\n",
    "data = pd.DataFrame({'nodes': myarray[:,0], 'layers': myarray[:,1], 'Z': myarray[:,2]})\n",
    "data_pivoted = data.pivot(\"nodes\", \"layers\", \"Z\")\n",
    "#vmin,vmax changed just to show mainly the ones above 0.9\n",
    "ax = sns.heatmap(data_pivoted,vmin=0.9, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heat map shows which models had the best accuracy. I have the z variable (accuracy) plotted from 0.9-1.0. So any that are not black were found to be above 0.9 accuracy score. \n",
    "As seen above all models showed a high accuracy score above 0.9 if the nodes used were above 1. The lighter the color the better accuracy.\n",
    "If you see in my for loop above, I put in an if statement that if I happen to have a model that is a perfect fit, which I had seen occur while testing different things. So I happened to know that there were perfect models. However, the code below still prints the best fit models if there aren't and models that have a perfect fit.\n",
    "\n",
    "I chose the first instance of a perfect model to test on the unknownwine data set, because I assume that the lowest node/layer model that is a perfect fit will be faster and more efficient than any models that are also perfect but have more nodes/layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes used 2, and layers used 2 in best fit model\n",
      "\n",
      "\n",
      "Confusion matrix for best fit model\n",
      "[[10  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Classification report for best fit model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "Own calculations (printed in cell 2 steps above as well) to verify the classification report\n",
      "[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]]\n",
      "\n",
      "Predictions for the unknownwine data using this model\n",
      "['class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0']\n",
      "\n",
      "Probability for each class for the unknown data\n",
      "\n",
      "[[1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 9.28227907e-240 4.72576368e-224]\n",
      " [1.00000000e+000 7.75169074e-171 1.99847136e-159]\n",
      " [1.00000000e+000 1.36312319e-095 7.18154531e-089]\n",
      " [1.00000000e+000 1.12122409e-176 6.68268173e-165]\n",
      " [1.00000000e+000 7.06280346e-051 6.07929008e-047]\n",
      " [1.00000000e+000 5.26109020e-115 4.49462517e-107]\n",
      " [1.00000000e+000 4.03748603e-038 5.57062943e-035]\n",
      " [1.00000000e+000 6.50927848e-110 2.67772230e-102]\n",
      " [1.00000000e+000 8.06430915e-082 5.88727600e-076]]\n"
     ]
    }
   ],
   "source": [
    "#if there was a perfect fit then print info for the best fit model\n",
    "if first == 1:\n",
    "    print ('Nodes used %s, and layers used %s in best fit model\\n' % (bestfit[0],bestfit[1]))\n",
    "    print ('\\nConfusion matrix for best fit model')\n",
    "    print bestconf\n",
    "    print ('\\nClassification report for best fit model')\n",
    "    print bestx\n",
    "    print ('\\nOwn calculations (printed in cell 2 steps above as well) to verify the classification report')\n",
    "    print (bestowncalcs)\n",
    "    print ('\\nPredictions for the unknownwine data using this model')\n",
    "    print classprediction\n",
    "    print ('\\nProbability for each class for the unknown data\\n')\n",
    "    print prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the classification report for the best fit model I can see\n",
    "that the instances of class 0,1,2 are almost even. So I can assume that this\n",
    "is well balanced to use as a classifier for each class.\n",
    "\n",
    "Also, looking at the probabilites of each class for each unknown printed\n",
    "above I can see that the unknown predicted has a high probability for \n",
    "being correct and the probabilites aren't too close for the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n",
      "['class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0']\n",
      "[[1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 5.14006293e-308 1.46914476e-312]\n",
      " [1.00000000e+000 2.34118971e-209 1.46663384e-212]\n",
      " [1.00000000e+000 1.87290559e-122 5.64651702e-120]\n",
      " [1.00000000e+000 4.93224563e-199 2.80965818e-198]\n",
      " [1.00000000e+000 2.66020359e-063 6.28790482e-064]\n",
      " [1.00000000e+000 2.25831483e-164 4.54518791e-165]\n",
      " [1.00000000e+000 1.35702545e-019 9.36191022e-035]\n",
      " [1.00000000e+000 2.33771070e-130 2.26763928e-129]\n",
      " [1.00000000e+000 5.19512882e-099 2.09197544e-097]]\n"
     ]
    }
   ],
   "source": [
    "#use best model to train data and return accuracy\n",
    "#this is done by hand if there was no perfect fit\n",
    "\n",
    "#This is for if there isn't a perfect fit, decide which one is the best fit\n",
    "#from the above printing of Precision, Recall, Fmeasure for each model\n",
    "#above 0.9\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100),max_iter=1000,random_state=4)\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "accresults = metrics.accuracy_score(y_test,predictions)\n",
    "print accresults\n",
    "metrics.classification_report(y_test, predictions)\n",
    "unkprediction = mlp.predict(unknownwine)\n",
    "classprediction = []\n",
    "for i in unkprediction:\n",
    "    tname = targetnamelist[i]\n",
    "    classprediction.append(tname)\n",
    "print classprediction\n",
    "print mlp.predict_proba(unknownwine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
